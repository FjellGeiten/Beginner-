{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nordic Exchange Oslo 1st Data Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader før rensing: 318\n",
      "Antall rader etter filtrering (kun Ordinary Shares): 307\n",
      "Antall rader etter fjerning av duplikater: 304\n",
      "Det rensede datasettet er lagret som /Users/k.a.h/Desktop/OsloExchange_PrimaryCleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sett inn filbanen til datasettet ditt\n",
    "file_path = \"/Users/k.a.h/Desktop/MasterData/OsloExchange_Primary1.xlsx\"  # Oppdater for andre land\n",
    "\n",
    "# Les inn Excel-filen\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filtrer for selskaper med \"Ordinary Shares\" i \"Type of Equity\"\n",
    "df_filtered = df[df['Type of Equity'] == 'Ordinary Share']\n",
    "\n",
    "# Fjern selskaper uten verdi i \"Market Cap (USD)\" eller med \"--\"\n",
    "df_filtered = df_filtered[df_filtered['Market Cap (USD)'] != \"--\"]  # Fjern rader med \"--\"\n",
    "df_filtered = df_filtered.dropna(subset=['Market Cap (USD)'])  # Fjern rader med NaN i \"Market Cap (USD)\"\n",
    "\n",
    "# Fjern duplikater basert på \"Issuer\", behold kun første forekomst\n",
    "df_cleaned = df_filtered.drop_duplicates(subset=['Issuer'], keep='first')\n",
    "\n",
    "# Sjekk antall rader før og etter rensing\n",
    "print(f\"Antall rader før rensing: {len(df)}\")\n",
    "print(f\"Antall rader etter filtrering (kun Ordinary Shares): {len(df_filtered)}\")\n",
    "print(f\"Antall rader etter fjerning av duplikater: {len(df_cleaned)}\")\n",
    "\n",
    "# Lagre det rensede datasettet\n",
    "output_path = \"/Users/k.a.h/Desktop/OsloExchange_PrimaryCleaned.xlsx\"  # Endre filnavn for andre land\n",
    "df_cleaned.to_excel(output_path, index=False, sheet_name=\"Cleaned Data\")\n",
    "\n",
    "print(f\"Det rensede datasettet er lagret som {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nordic Exchange Stockholm 1st Data Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader før rensing: 769\n",
      "Antall rader etter filtrering (kun Ordinary Shares): 759\n",
      "Antall rader etter fjerning av duplikater: 717\n",
      "Det rensede datasettet er lagret som /Users/k.a.h/Desktop/StockholmExchange_PrimaryCleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Sverige\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sett inn filbanen til datasettet ditt\n",
    "file_path = \"/Users/k.a.h/Desktop/MasterData/StockholmExchange_Primary1.xlsx\"  # Oppdater for andre land\n",
    "\n",
    "# Les inn Excel-filen\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filtrer for selskaper med \"Ordinary Shares\" i \"Type of Equity\"\n",
    "df_filtered = df[df['Type of Equity'] == 'Ordinary Share']\n",
    "\n",
    "# Fjern selskaper uten verdi i \"Market Cap (USD)\" eller med \"--\"\n",
    "df_filtered = df_filtered[df_filtered['Market Cap (USD)'] != \"--\"]  # Fjern rader med \"--\"\n",
    "df_filtered = df_filtered.dropna(subset=['Market Cap (USD)'])  # Fjern rader med NaN i \"Market Cap (USD)\"\n",
    "\n",
    "# Fjern duplikater basert på \"Issuer\", behold kun første forekomst\n",
    "df_cleaned = df_filtered.drop_duplicates(subset=['Issuer'], keep='first')\n",
    "\n",
    "# Sjekk antall rader før og etter rensing\n",
    "print(f\"Antall rader før rensing: {len(df)}\")\n",
    "print(f\"Antall rader etter filtrering (kun Ordinary Shares): {len(df_filtered)}\")\n",
    "print(f\"Antall rader etter fjerning av duplikater: {len(df_cleaned)}\")\n",
    "\n",
    "# Lagre det rensede datasettet\n",
    "output_path = \"/Users/k.a.h/Desktop/StockholmExchange_PrimaryCleaned.xlsx\"  # Endre filnavn for andre land\n",
    "df_cleaned.to_excel(output_path, index=False, sheet_name=\"Cleaned Data\")\n",
    "\n",
    "print(f\"Det rensede datasettet er lagret som {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nordic Exchange Helsinki 1st Data Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader før rensing: 190\n",
      "Antall rader etter filtrering (kun Ordinary Shares): 185\n",
      "Antall rader etter fjerning av duplikater: 175\n",
      "Det rensede datasettet er lagret som /Users/k.a.h/Desktop/HelsinkiExchange_PrimaryCleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Finland \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sett inn filbanen til datasettet ditt\n",
    "file_path = \"/Users/k.a.h/Desktop/MasterData/HelsinkiExchange_Primary1.xlsx\"  # Oppdater for andre land\n",
    "\n",
    "# Les inn Excel-filen\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filtrer for selskaper med \"Ordinary Shares\" i \"Type of Equity\"\n",
    "df_filtered = df[df['Type of Equity'] == 'Ordinary Share']\n",
    "\n",
    "# Fjern selskaper uten verdi i \"Market Cap (USD)\" eller med \"--\"\n",
    "df_filtered = df_filtered[df_filtered['Market Cap (USD)'] != \"--\"]  # Fjern rader med \"--\"\n",
    "df_filtered = df_filtered.dropna(subset=['Market Cap (USD)'])  # Fjern rader med NaN i \"Market Cap (USD)\"\n",
    "\n",
    "# Fjern duplikater basert på \"Issuer\", behold kun første forekomst\n",
    "df_cleaned = df_filtered.drop_duplicates(subset=['Issuer'], keep='first')\n",
    "\n",
    "# Sjekk antall rader før og etter rensing\n",
    "print(f\"Antall rader før rensing: {len(df)}\")\n",
    "print(f\"Antall rader etter filtrering (kun Ordinary Shares): {len(df_filtered)}\")\n",
    "print(f\"Antall rader etter fjerning av duplikater: {len(df_cleaned)}\")\n",
    "\n",
    "# Lagre det rensede datasettet\n",
    "output_path = \"/Users/k.a.h/Desktop/HelsinkiExchange_PrimaryCleaned.xlsx\"  # Endre filnavn for andre land\n",
    "df_cleaned.to_excel(output_path, index=False, sheet_name=\"Cleaned Data\")\n",
    "\n",
    "print(f\"Det rensede datasettet er lagret som {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nordic Exchange Copenhagen 1st Data Extraction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rader før rensing: 161\n",
      "Antall rader etter filtrering (kun Ordinary Shares): 157\n",
      "Antall rader etter fjerning av duplikater: 152\n",
      "Det rensede datasettet er lagret som /Users/k.a.h/Desktop/CopenhagenExchange_PrimaryCleaned.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sett inn filbanen til datasettet ditt\n",
    "file_path = \"/Users/k.a.h/Desktop/MasterData/CopenhagenExchange_Primary1.xlsx\"  # Oppdater for andre land\n",
    "\n",
    "# Les inn Excel-filen\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filtrer for selskaper med \"Ordinary Shares\" i \"Type of Equity\"\n",
    "df_filtered = df[df['Type of Equity'] == 'Ordinary Share']\n",
    "\n",
    "# Fjern selskaper uten verdi i \"Market Cap (USD)\" eller med \"--\"\n",
    "df_filtered = df_filtered[df_filtered['Market Cap (USD)'] != \"--\"]  # Fjern rader med \"--\"\n",
    "df_filtered = df_filtered.dropna(subset=['Market Cap (USD)'])  # Fjern rader med NaN i \"Market Cap (USD)\"\n",
    "\n",
    "# Fjern duplikater basert på \"Issuer\", behold kun første forekomst\n",
    "df_cleaned = df_filtered.drop_duplicates(subset=['Issuer'], keep='first')\n",
    "\n",
    "# Sjekk antall rader før og etter rensing\n",
    "print(f\"Antall rader før rensing: {len(df)}\")\n",
    "print(f\"Antall rader etter filtrering (kun Ordinary Shares): {len(df_filtered)}\")\n",
    "print(f\"Antall rader etter fjerning av duplikater: {len(df_cleaned)}\")\n",
    "\n",
    "# Lagre det rensede datasettet\n",
    "output_path = \"/Users/k.a.h/Desktop/CopenhagenExchange_PrimaryCleaned.xlsx\"  # Endre filnavn for andre land\n",
    "df_cleaned.to_excel(output_path, index=False, sheet_name=\"Cleaned Data\")\n",
    "\n",
    "print(f\"Det rensede datasettet er lagret som {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Decile Structure (Denmark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date      Ticker    Market Cap  Decile  Micro-Cap  Small-Cap  \\\n",
      "0    2023-12-31   SVITZR.CO  0.000000e+00       1          1          0   \n",
      "1    2023-12-31   CONFRZ.CO  3.919137e+00       1          1          0   \n",
      "2    2023-12-31    MONSO.CO  8.833089e+00       1          1          0   \n",
      "3    2023-12-31     ATLA.CO  1.002120e+01       1          1          0   \n",
      "4    2023-12-31     NTRb.CO  1.064417e+01       1          1          0   \n",
      "..          ...         ...           ...     ...        ...        ...   \n",
      "147  2023-12-31    COLOb.CO  1.622744e+05      10          0          0   \n",
      "148  2023-12-31  MAERSKb.CO  2.116792e+05      10          0          0   \n",
      "149  2023-12-31      VWS.CO  2.164146e+05      10          0          0   \n",
      "150  2023-12-31      DSV.CO  2.596245e+05      10          0          0   \n",
      "151  2023-12-31    NOVOb.CO  2.398063e+06      10          0          0   \n",
      "\n",
      "     Mid-Cap  Large-Cap  \n",
      "0          0          0  \n",
      "1          0          0  \n",
      "2          0          0  \n",
      "3          0          0  \n",
      "4          0          0  \n",
      "..       ...        ...  \n",
      "147        0          1  \n",
      "148        0          1  \n",
      "149        0          1  \n",
      "150        0          1  \n",
      "151        0          1  \n",
      "\n",
      "[152 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "denmark_file = '/Users/k.a.h/Desktop/MasterData/Useful Data/Factors Denmark.xlsx'  # Replace with your file path\n",
    "denmark_data = pd.ExcelFile(denmark_file).parse()\n",
    "\n",
    "# Replace missing values with 0 to indicate not listed that year\n",
    "denmark_data_filled = denmark_data.fillna(0)\n",
    "\n",
    "# Define size category thresholds (can be adjusted as needed)\n",
    "MICRO_CAP_THRESHOLD = 300  # in millions\n",
    "SMALL_CAP_THRESHOLD = 2000\n",
    "MID_CAP_THRESHOLD = 10000\n",
    "\n",
    "# Function to process deciles and size categories for a specific year\n",
    "def process_deciles_and_size_categories(data, year):\n",
    "    \"\"\"\n",
    "    Process deciles and size categories for a given dataset and year.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): The dataset containing market cap information.\n",
    "        year (str): The year to process (e.g., '2023-12-31').\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with Date, Ticker, Market Cap, Decile, and Size Category dummies.\n",
    "    \"\"\"\n",
    "    # Filter the data for the specified year\n",
    "    data_for_year = data[data[\"Date\"] == year].drop(columns=[\"Date\"]).T\n",
    "    data_for_year.columns = [\"Market Cap\"]\n",
    "    data_for_year[\"Ticker\"] = data_for_year.index\n",
    "    \n",
    "    # Sort by market capitalization\n",
    "    data_for_year = data_for_year.sort_values(by=\"Market Cap\")\n",
    "    \n",
    "    # Assign deciles based on market capitalization\n",
    "    data_for_year[\"Decile\"] = pd.qcut(\n",
    "        data_for_year[\"Market Cap\"], 10, labels=False, duplicates='drop'\n",
    "    ) + 1  # Deciles range from 1 to 10\n",
    "    \n",
    "    # Assign size categories\n",
    "    data_for_year[\"Micro-Cap\"] = (data_for_year[\"Market Cap\"] < MICRO_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Small-Cap\"] = ((data_for_year[\"Market Cap\"] >= MICRO_CAP_THRESHOLD) &\n",
    "                                  (data_for_year[\"Market Cap\"] < SMALL_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Mid-Cap\"] = ((data_for_year[\"Market Cap\"] >= SMALL_CAP_THRESHOLD) &\n",
    "                                (data_for_year[\"Market Cap\"] < MID_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Large-Cap\"] = (data_for_year[\"Market Cap\"] >= MID_CAP_THRESHOLD).astype(int)\n",
    "    \n",
    "    # Add the year for context\n",
    "    data_for_year[\"Date\"] = year\n",
    "    \n",
    "    # Reorder columns for clarity\n",
    "    data_for_year = data_for_year[[\"Date\", \"Ticker\", \"Market Cap\", \"Decile\", \"Micro-Cap\", \"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]]\n",
    "    \n",
    "    return data_for_year.reset_index(drop=True)\n",
    "\n",
    "# Example: Process for Denmark in 2023\n",
    "denmark_deciles_2023 = process_deciles_and_size_categories(denmark_data_filled, \"2023-12-31\")\n",
    "\n",
    "# Save the results to a CSV file for further use\n",
    "denmark_deciles_2023.to_csv(\"Denmark_Deciles_and_Size_Categories_2023.csv\", index=False)\n",
    "\n",
    "# Display the results\n",
    "print(denmark_deciles_2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for Deciles and Size of All Available Years (Denmark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file with sheets ordered by descending years has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "denmark_file = '/Users/k.a.h/Desktop/MasterData/Useful Data/Factors Denmark.xlsx'  # Replace with your file path\n",
    "denmark_data = pd.ExcelFile(denmark_file).parse()\n",
    "\n",
    "# Replace missing values with 0 to indicate not listed that year\n",
    "denmark_data_filled = denmark_data.fillna(0)\n",
    "\n",
    "# Define size category thresholds\n",
    "MICRO_CAP_THRESHOLD = 300  # in millions\n",
    "SMALL_CAP_THRESHOLD = 2000\n",
    "MID_CAP_THRESHOLD = 10000\n",
    "\n",
    "# Function to process deciles and size categories for a specific year\n",
    "def process_deciles_and_size_categories(data, year):\n",
    "    data_for_year = data[data[\"Date\"] == year].drop(columns=[\"Date\"]).T\n",
    "    data_for_year.columns = [\"Market Cap\"]\n",
    "    data_for_year[\"Ticker\"] = data_for_year.index\n",
    "    data_for_year = data_for_year.sort_values(by=\"Market Cap\")\n",
    "    data_for_year[\"Decile\"] = pd.qcut(data_for_year[\"Market Cap\"], 10, labels=False, duplicates='drop') + 1\n",
    "    data_for_year[\"Micro-Cap\"] = (data_for_year[\"Market Cap\"] < MICRO_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Small-Cap\"] = ((data_for_year[\"Market Cap\"] >= MICRO_CAP_THRESHOLD) &\n",
    "                                  (data_for_year[\"Market Cap\"] < SMALL_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Mid-Cap\"] = ((data_for_year[\"Market Cap\"] >= SMALL_CAP_THRESHOLD) &\n",
    "                                (data_for_year[\"Market Cap\"] < MID_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Large-Cap\"] = (data_for_year[\"Market Cap\"] >= MID_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Date\"] = year\n",
    "    data_for_year = data_for_year[[\"Date\", \"Ticker\", \"Market Cap\", \"Decile\", \"Micro-Cap\", \"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]]\n",
    "    return data_for_year.reset_index(drop=True)\n",
    "\n",
    "# List of years to process, sorted in descending order\n",
    "years = sorted(denmark_data[\"Date\"].unique(), reverse=True)\n",
    "\n",
    "# Create an Excel writer to store multiple sheets\n",
    "with pd.ExcelWriter(\"Denmark_Size_Categories.xlsx\") as writer:\n",
    "    for year in years:\n",
    "        year_data = process_deciles_and_size_categories(denmark_data_filled, year)\n",
    "        sheet_name = str(year)[:4]  # Use the year as the sheet name\n",
    "        year_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Excel file with sheets ordered by descending years has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciles and Size - Norway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'Norway_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "norway_file = '/Users/k.a.h/Desktop/MasterData/Useful Data/Factors Norway.xlsx'  # Replace with your file path\n",
    "norway_data = pd.ExcelFile(norway_file).parse()\n",
    "\n",
    "# Replace missing values with 0 to indicate not listed that year\n",
    "norway_data_filled = norway_data.fillna(0)\n",
    "\n",
    "# Define size category thresholds\n",
    "MICRO_CAP_THRESHOLD = 300  # in millions\n",
    "SMALL_CAP_THRESHOLD = 2000\n",
    "MID_CAP_THRESHOLD = 10000\n",
    "\n",
    "# Function to process deciles and size categories for a specific year\n",
    "def process_deciles_and_size_categories(data, year):\n",
    "    data_for_year = data[data[\"Date\"] == year].drop(columns=[\"Date\"]).T\n",
    "    data_for_year.columns = [\"Market Cap\"]\n",
    "    data_for_year[\"Ticker\"] = data_for_year.index\n",
    "    data_for_year = data_for_year.sort_values(by=\"Market Cap\")\n",
    "    data_for_year[\"Decile\"] = pd.qcut(data_for_year[\"Market Cap\"], 10, labels=False, duplicates='drop') + 1\n",
    "    data_for_year[\"Micro-Cap\"] = (data_for_year[\"Market Cap\"] < MICRO_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Small-Cap\"] = ((data_for_year[\"Market Cap\"] >= MICRO_CAP_THRESHOLD) &\n",
    "                                  (data_for_year[\"Market Cap\"] < SMALL_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Mid-Cap\"] = ((data_for_year[\"Market Cap\"] >= SMALL_CAP_THRESHOLD) &\n",
    "                                (data_for_year[\"Market Cap\"] < MID_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Large-Cap\"] = (data_for_year[\"Market Cap\"] >= MID_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Date\"] = year\n",
    "    data_for_year = data_for_year[[\"Date\", \"Ticker\", \"Market Cap\", \"Decile\", \"Micro-Cap\", \"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]]\n",
    "    return data_for_year.reset_index(drop=True)\n",
    "\n",
    "# List of years to process, sorted in descending order\n",
    "years = sorted(norway_data[\"Date\"].unique(), reverse=True)\n",
    "\n",
    "# Create an Excel writer to store multiple sheets\n",
    "with pd.ExcelWriter(\"Norway_Size_Categories.xlsx\") as writer:\n",
    "    for year in years:\n",
    "        year_data = process_deciles_and_size_categories(norway_data_filled, year)\n",
    "        sheet_name = str(year)[:4]  # Use the year as the sheet name\n",
    "        year_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Excel file 'Norway_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciles and Size - Sweden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'Sweden_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "sweden_file = '/Users/k.a.h/Desktop/MasterData/Useful Data/Factors Sweden.xlsx'  # Replace with your file path\n",
    "sweden_data = pd.ExcelFile(sweden_file).parse()\n",
    "\n",
    "# Replace missing values with 0 to indicate not listed that year\n",
    "sweden_data_filled = sweden_data.fillna(0)\n",
    "\n",
    "# Define size category thresholds\n",
    "MICRO_CAP_THRESHOLD = 300  # in millions\n",
    "SMALL_CAP_THRESHOLD = 2000\n",
    "MID_CAP_THRESHOLD = 10000\n",
    "\n",
    "# Function to process deciles and size categories for a specific year\n",
    "def process_deciles_and_size_categories(data, year):\n",
    "    data_for_year = data[data[\"Date\"] == year].drop(columns=[\"Date\"]).T\n",
    "    data_for_year.columns = [\"Market Cap\"]\n",
    "    data_for_year[\"Ticker\"] = data_for_year.index\n",
    "    data_for_year = data_for_year.sort_values(by=\"Market Cap\")\n",
    "    data_for_year[\"Decile\"] = pd.qcut(data_for_year[\"Market Cap\"], 10, labels=False, duplicates='drop') + 1\n",
    "    data_for_year[\"Micro-Cap\"] = (data_for_year[\"Market Cap\"] < MICRO_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Small-Cap\"] = ((data_for_year[\"Market Cap\"] >= MICRO_CAP_THRESHOLD) &\n",
    "                                  (data_for_year[\"Market Cap\"] < SMALL_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Mid-Cap\"] = ((data_for_year[\"Market Cap\"] >= SMALL_CAP_THRESHOLD) &\n",
    "                                (data_for_year[\"Market Cap\"] < MID_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Large-Cap\"] = (data_for_year[\"Market Cap\"] >= MID_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Date\"] = year\n",
    "    data_for_year = data_for_year[[\"Date\", \"Ticker\", \"Market Cap\", \"Decile\", \"Micro-Cap\", \"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]]\n",
    "    return data_for_year.reset_index(drop=True)\n",
    "\n",
    "# List of years to process, sorted in descending order\n",
    "years = sorted(sweden_data[\"Date\"].unique(), reverse=True)\n",
    "\n",
    "# Create an Excel writer to store multiple sheets\n",
    "with pd.ExcelWriter(\"Sweden_Size_Categories.xlsx\") as writer:\n",
    "    for year in years:\n",
    "        year_data = process_deciles_and_size_categories(sweden_data_filled, year)\n",
    "        sheet_name = str(year)[:4]  # Use the year as the sheet name\n",
    "        year_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Excel file 'Sweden_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciles and Size - Finland "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'Finland_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "finland_file = '/Users/k.a.h/Desktop/MasterData/Useful Data/Factors Finland.xlsx'  # Replace with your file path\n",
    "finland_data = pd.ExcelFile(finland_file).parse()\n",
    "\n",
    "# Replace missing values with 0 to indicate not listed that year\n",
    "finland_data_filled = finland_data.fillna(0)\n",
    "\n",
    "# Define size category thresholds\n",
    "MICRO_CAP_THRESHOLD = 300  # in millions\n",
    "SMALL_CAP_THRESHOLD = 2000\n",
    "MID_CAP_THRESHOLD = 10000\n",
    "\n",
    "# Function to process deciles and size categories for a specific year\n",
    "def process_deciles_and_size_categories(data, year):\n",
    "    data_for_year = data[data[\"Date\"] == year].drop(columns=[\"Date\"]).T\n",
    "    data_for_year.columns = [\"Market Cap\"]\n",
    "    data_for_year[\"Ticker\"] = data_for_year.index\n",
    "    data_for_year = data_for_year.sort_values(by=\"Market Cap\")\n",
    "    data_for_year[\"Decile\"] = pd.qcut(data_for_year[\"Market Cap\"], 10, labels=False, duplicates='drop') + 1\n",
    "    data_for_year[\"Micro-Cap\"] = (data_for_year[\"Market Cap\"] < MICRO_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Small-Cap\"] = ((data_for_year[\"Market Cap\"] >= MICRO_CAP_THRESHOLD) &\n",
    "                                  (data_for_year[\"Market Cap\"] < SMALL_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Mid-Cap\"] = ((data_for_year[\"Market Cap\"] >= SMALL_CAP_THRESHOLD) &\n",
    "                                (data_for_year[\"Market Cap\"] < MID_CAP_THRESHOLD)).astype(int)\n",
    "    data_for_year[\"Large-Cap\"] = (data_for_year[\"Market Cap\"] >= MID_CAP_THRESHOLD).astype(int)\n",
    "    data_for_year[\"Date\"] = year\n",
    "    data_for_year = data_for_year[[\"Date\", \"Ticker\", \"Market Cap\", \"Decile\", \"Micro-Cap\", \"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]]\n",
    "    return data_for_year.reset_index(drop=True)\n",
    "\n",
    "# List of years to process, sorted in descending order\n",
    "years = sorted(finland_data[\"Date\"].unique(), reverse=True)\n",
    "\n",
    "# Create an Excel writer to store multiple sheets\n",
    "with pd.ExcelWriter(\"Finland_Size_Categories.xlsx\") as writer:\n",
    "    for year in years:\n",
    "        year_data = process_deciles_and_size_categories(finland_data_filled, year)\n",
    "        sheet_name = str(year)[:4]  # Use the year as the sheet name\n",
    "        year_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(\"Excel file 'Finland_Size_Categories.xlsx' with sheets ordered by descending years has been created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
